1. Чтобы при обновлении всегда было минимальное количество pod такое же как в `spec.replicas` нужно выставить: `spec.strategy.rollingUpdate.maxUnavailable: 0`
2. Настройте [Readiness и Startup](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) пробы чтобы избежать ошибок таких как отправка трафика на pod приложение в котором еще не запущенно (Liveness пробу нужно ставить только в том случае если лучше что можно сделать это убить контейнер)
3. Для того чтобы k8s успел убрать pod из endpoint для service перед отправкой SIGTERM сигнала необходимо добавить sleep перед остановкой (который значительно меньше `terminationGracePeriodSeconds`) чтобы избежать ошибки в случаях:
   - когда HPA уменьшает количество pod 
   - удалении старых pod при обновлении

   Для версии ниже 1.29
    ```yaml
    spec:
      template:
        spec:
          terminationGracePeriodSeconds: 45
          containers:
            - name: myapp
              lifecycle:
                preStop:
                  exec:
                    command:
                      - /bin/sh
                      - '-c'
                      - /bin/sleep 15
    ```
    Для версии 1.29+
    ```yaml
    spec:
      template:
        spec:
          terminationGracePeriodSeconds: 35
          containers:
            - name: myapp
              lifecycle:
                preStop:
                  sleep:
                    seconds: 5
    ```
4. Не забывайте выставлять limits и requests для ваших контейнеров в pod чтобы k8s использовал requests для планирования, а limits для ограничения конкуренции за ресурсов на node (простой способ как подобрать написано выше в Deployment) 
5. Настройте HPA для вашего Deployment с запасом 2х от текущей нагрузки (по результатам нагрузочного тестирования)
   > **Например:** с максимальной дневной нагрузкой за 7 дней справляются 6 pod, выставляем `maxReplicas: 12` (смотрим чтобы не было блокеров, например чтобы не закончились подключения к БД и тд)
6. HorizontalPodAutoscaler: стабилизация scaleDown - предотвращаем «резкое» убийство pod при кратковременном просадке RPS.

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 6
  maxReplicas: 12
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 600   # 10 минут «запаса»
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

- `stabilizationWindowSeconds` – время, в течение которого HPA **игнорирует** старые пики нагрузки перед тем как уменьшать реплики.
- Рекомендуемое значение: **≥ 600 сек** для большинства веб-приложений.
7. PodDisruptionBudget (PDB) - защита от «слишком агрессивных» drain/upgrade узлов (node).

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  minAvailable: 2   # или "50%"
  selector:
    matchLabels:
      app: myapp
```

- `minAvailable` / `maxUnavailable` – выбирайте так, чтобы при любом событии (kubectl drain, обновление ASG, Cluster Autoscaler) **оставалось минимально допустимое количество pod**.
- Всегда ставьте PDB для критичных Deployment.
8. TopologySpreadConstraints - исключаем одновременный падение всех pod одного Deployment на одном узле/зоне.

```yaml
spec:
  template:
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone   # или "kubernetes.io/hostname"
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: myapp
```
9. Service-mesh: circuit breaker / outlier detection - защита от «каскадных» ошибок при медленных запросах или упавших pod.

```yaml
# Istio
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-cb
spec:
  host: myapp
  trafficPolicy:
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
```

- `consecutiveErrors` – сколько подряд 5xx/timeout’ов нужно, чтобы sidecar **выкинул** pod из пула.
- `maxEjectionPercent` – максимально допустимый процент «выкинутых» pod (50 % = безопасный запас).

```yaml
# Linkerd
apiVersion: policy.linkerd.io/v1beta3
kind: HTTPRoute
metadata:
  name: myapp-cb
spec:
  parentRefs:
  - name: myapp-svc
    kind: Service
  rules:
  - backendRefs:
    - name: myapp
      port: 80
    timeouts:
      request: 2s
    retries:
      attempts: 2
    circuitBreaker:
      consecutiveFailures: 5
      backoff:
        minPenalty: 5s
        maxPenalty: 30s
```
